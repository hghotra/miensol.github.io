{"componentChunkName":"component---src-templates-post-template-tsx","path":"/setting-up-fluentd-elasticsearch-and-kibana-on-azure/","result":{"data":{"markdownRemark":{"id":"a99f1fa2-deb5-59fc-a1c1-939664a75794","html":"<p>A decent way too go through log files can come handy in various ways. From debugging bugs, investigating problems on production environment to figuring out where performance bottle necks are.\nFor simple cases when there is only one log file involved you can go very far with using grep/awk/sed magic or any decent editor capable of handling regex in large files.</p>\n<p>It becomes tricky however when your logs are scattered through several files, maybe use different log format or stamp entries with different timezones.\nFortunately there are services like <a href=\"http://www.splunk.com/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Splunk</a>, <a href=\"https://www.loggly.com/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Loggly</a> and many others that take away great amount of pain involved in aggregating distributed log entries and searching through them.</p>\n<p>I was searching once for a free alternative that I could quickly get up and running in our test environment where we had 10+ machines running 20+ web sites or services that we’re all part of a single product. That’s when I found out about <a href=\"http://www.elasticsearch.org/overview/kibana/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Kibana</a>, <a href=\"http://logstash.net/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">logstash</a>  and how they make use of <a href=\"http://www.elasticsearch.org/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">elasticsearch</a>.</p>\n<p>Back then I considered using <a href=\"http://fluentd.org/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">fluentd</a> instead of logstash however most of the machines we were running windows and that is not where fluentd shines. Nowadays I’m using linux vm mostly that’s why I decided to use fluentd.</p>\n<h2 id=\"setup-a-vm-for-elasticsearch\" style=\"position:relative;\"><a href=\"#setup-a-vm-for-elasticsearch\" aria-label=\"setup a vm for elasticsearch permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Setup a vm for elasticsearch</h2>\n<p>We need a machine that will store our aggregated log entries so let’s create one using <a href=\"http://azure.microsoft.com/en-us/documentation/articles/xplat-cli/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Azure Cross-Platform Command-Line interface</a>. After installing it with <code class=\"language-text\">npm install azure-cli -g</code> we need to introduce ourself to it. The simplest way to do this is to issue <code class=\"language-text\">azure account download</code> which will open a browser to download your profile:\n<img src='/images/azure_account_download.png'>\nAfter that you’ll need to import the downloaded file with <code class=\"language-text\">npm account import /path/to/your/credentials.publishsettings</code>.</p>\n<p>I’m used to ubuntu so let’s find an machine image to use:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">azure vm image list <span class=\"token operator\">|</span> <span class=\"token function\">grep</span> Ubuntu-14\ndata:    b39f27a8b8c64d52b05eac6a62ebad85__Ubuntu-14_04-LTS-amd64-server-20140122.1-alpha2-en-us-30GB                          Public    Linux  \ndata:    b39f27a8b8c64d52b05eac6a62ebad85__Ubuntu-14_04-LTS-amd64-server-20140226.1-beta1-en-us-30GB                           Public    Linux  \ndata:    b39f27a8b8c64d52b05eac6a62ebad85__Ubuntu-14_04-LTS-amd64-server-20140326-beta2-en-us-30GB                             Public    Linux  \ndata:    b39f27a8b8c64d52b05eac6a62ebad85__Ubuntu-14_04-LTS-amd64-server-20140414-en-us-30GB                                   Public    Linux  \ndata:    b39f27a8b8c64d52b05eac6a62ebad85__Ubuntu-14_04-LTS-amd64-server-20140416.1-en-us-30GB                                 Public    Linux  \ndata:    b39f27a8b8c64d52b05eac6a62ebad85__Ubuntu-14_04-LTS-amd64-server-20140528-en-us-30GB                                   Public    Linux  </code></pre></div>\n<p>The last one looks like most recent so we’ll used that. Next we need to create a virtual machine. We can use either password authentication (which isn’t recommended) or a ssh certificate. To use the latter we need to create a certificate key pair first. Openssl command line tool will do it for us:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">openssl req -x509 -nodes -days <span class=\"token number\">730</span> -newkey rsa:2048 -keyout ~/.ssh/mymachine.key -out ~/.ssh/mymachine.pem</code></pre></div>\n<p>It’s now time to issue azure to create a new instance of Ubuntu machine for us:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">azure vm create machine-dns-name b39f27a8b8c64d52b05eac6a62ebad85__Ubuntu-14_04-LTS-amd64-server-20140528-en-us-30GB machineuser <span class=\"token punctuation\">\\</span>\n  --vm-size extrasmall <span class=\"token punctuation\">\\</span>\n  --location <span class=\"token string\">'North Europe'</span> <span class=\"token punctuation\">\\</span>\n  --ssh <span class=\"token number\">22</span> --no-ssh-password --ssh-cert ~/.ssh/mymachine.pem\n\ninfo:    Executing <span class=\"token builtin class-name\">command</span> vm create\n+ Looking up image b39f27a8b8c64d52b05eac6a62ebad85__Ubuntu-14_04-LTS-amd64-server-20140528-en-us-30GB\n+ Looking up cloud <span class=\"token function\">service</span>\n+ Creating cloud <span class=\"token function\">service</span>\n+ Retrieving storage accounts\n+ Configuring certificate\n+ Creating VM\ninfo:    vm create <span class=\"token builtin class-name\">command</span> OK</code></pre></div>\n<p>We can find out more details about our newly created machine with: <code class=\"language-text\">azure vm list --dns-name machine-dns-name --json</code>.\nOur machine is up and running to so we can log into it using ssh (before you do that be sure to change .key file permission to 0600 so that only you can access it): <code class=\"language-text\">ssh -i ~/.ssh/mymachine.key  machineuser@machine-dns-name.cloudapp.net</code></p>\n<h2 id=\"install-elasticsearch\" style=\"position:relative;\"><a href=\"#install-elasticsearch\" aria-label=\"install elasticsearch permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Install elasticsearch</h2>\n<p>First let’s download elasticsearch and extract it to our newly created vm:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">curl</span> https://download.elasticsearch.org/elasticsearch/elasticsearch/elasticsearch-1.2.0.zip -o elasticsearch-1.2.0.zip\n<span class=\"token function\">unzip</span> elasticsearch-1.2.0.zip</code></pre></div>\n<p>To run elasticsearch we’ll need java in version at least 1.7:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">sudo</span> <span class=\"token function\">apt-get</span> update\n<span class=\"token function\">sudo</span> <span class=\"token function\">apt-get</span> <span class=\"token function\">install</span> default-jre</code></pre></div>\n<p>Now we can finally run elasticsearch:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">./elasticsearch-1.2.0/bin/elasticsearch</code></pre></div>\n<p>If we want to run elasticsearch as a daemon we can pass <code class=\"language-text\">-d</code> to the script. <em>(see below for init.d script)</em></p>\n<p>We also need to open port for elasticsearch:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">azure vm endpoint create --endpoint-name elasticsearch machine-dns-name <span class=\"token number\">9200</span> <span class=\"token number\">9200</span></code></pre></div>\n<p>We only wan’t our machines to be able to push logs to elasticsearch that’s why we need to add ACL rules to the endpoint we created above. Unfortunately I couldn’t find a way to do this through CLI interface so we need to resort to <a href=\"https://manage.windowsazure.com/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">web interface</a>.</p>\n<h2 id=\"install-kibana\" style=\"position:relative;\"><a href=\"#install-kibana\" aria-label=\"install kibana permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Install Kibana</h2>\n<p>Kibana is a web application designed to perform elasticsearch searches and display them using neat interface. It communicates with elasticsearch directly that’s why it’s not really suited to be deployed to publicly accessible place. Fortunately there is <a href=\"https://github.com/hmalphettes/kibana-proxy\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">kibana-proxy</a> which provides authentication on top of it. To run kibana-proxy we’ll need node.js let’s install both of them:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">sudo</span> <span class=\"token function\">apt-get</span> update\n<span class=\"token function\">sudo</span> <span class=\"token function\">apt-get</span> <span class=\"token function\">install</span> <span class=\"token function\">git</span>\n<span class=\"token function\">sudo</span> <span class=\"token function\">apt-get</span> <span class=\"token function\">install</span> nodejs\n<span class=\"token function\">sudo</span> <span class=\"token function\">apt-get</span> <span class=\"token function\">install</span> <span class=\"token function\">npm</span>\n\n<span class=\"token function\">git</span> clone https://github.com/hmalphettes/kibana-proxy.git\n<span class=\"token builtin class-name\">cd</span> kibana-proxy\n<span class=\"token function\">git</span> submodule init\n<span class=\"token function\">git</span> submodule update\n<span class=\"token function\">npm</span> <span class=\"token function\">install</span>\nnode app.js <span class=\"token operator\">&amp;</span></code></pre></div>\n<p>kibana-proxy is now running but in order to access it from outside we need to open firewall port:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">azure vm endpoint create --endpoint-name kibana-proxy machine-dns-name <span class=\"token number\">80</span> <span class=\"token number\">3003</span></code></pre></div>\n<p>Now when you point your browser to <code class=\"language-text\">http://machine-dns-name/</code> you should see kibana welcome screen.</p>\n<h2 id=\"restrict-access-to-kibana-proxy\" style=\"position:relative;\"><a href=\"#restrict-access-to-kibana-proxy\" aria-label=\"restrict access to kibana proxy permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Restrict access to kibana-proxy</h2>\n<p>You probably don’t want anyone to be able to see your logs that’s why we need to setup authentication. <code class=\"language-text\">kibana-proxy</code> implements this through Google OAuth - so let’s enable it for our installation. First we’ll need <code class=\"language-text\">APP_ID</code> (Client ID) and <code class=\"language-text\">APP_SECRET</code> (Client secret) so let’s go to <a href=\"https://console.developers.google.com/project\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">google developer console</a> and create a new project. Next we need to enable OAuth for our project in <em>APIs &#x26; auth > Credentials</em>:</p>\n<img src='/static/media/google_oauth_setup.png'>\n<p>Make sure <em>AUTHORIZED REDIRECT URI</em> looks like <code class=\"language-text\">http://machind-dns-name.cloudapp.net/auth/google/callback</code>. For more secure setup you should be using <code class=\"language-text\">https</code> but for simplicity we’ll skip that.</p>\n<p>Now we need to start <code class=\"language-text\">kibana-proxy</code> again this time passing it <code class=\"language-text\">APP_ID</code>, <code class=\"language-text\">APP_SECRET</code> along with <code class=\"language-text\">AUTHORIZED_EMAILS</code> through environment variables (<code class=\"language-text\">kibana-proxy-start.sh</code>):</p>\n<div id='kibana_proxy_start'>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">APP_ID</span><span class=\"token operator\">=</span>fill_me_appid\n<span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">APP_SECRET</span><span class=\"token operator\">=</span>fill_me_app_secret\n<span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">AUTHORIZED_EMAILS</span><span class=\"token operator\">=</span>my_email_list\n<span class=\"token builtin class-name\">exec</span> /usr/bin/nodejs app.js</code></pre></div>\n</div>\nNow when you go to `http://machine-dns-name/` you should get redirect to Google authorization page.\n<p>We want to run the <code class=\"language-text\">kibana-proxy</code> continuously - the simplest way to achieve that is to make use of <a href=\"https://github.com/nodejitsu/forever\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">forever</a> module. However in this guide we’ll use upstart scripts described below.</p>\n<h2 id=\"fluentd-installation\" style=\"position:relative;\"><a href=\"#fluentd-installation\" aria-label=\"fluentd installation permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Fluentd installation</h2>\n<p>To push log entries to our elasticsearch instance we need <code class=\"language-text\">fluentd</code> <em>agent</em> installed on the machine we want to gather logs from.\nFluentd <em>agent</em> comes in 2 forms: fluentd gem if you wish to have more control features and updates and td-agent if you care for stability over new features. We’ll go with fluentd gem for this guide.</p>\n<p>Since fluentd is implemented in Ruby with most performance critical parts written in C. To install it we need ruby first but obtaining it with rvm is a piece of cake:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">curl</span> -sSL https://get.rvm.io <span class=\"token operator\">|</span> <span class=\"token function\">bash</span> -s stable\n<span class=\"token builtin class-name\">source</span> ~/.rvm/scripts/rvm\nrvm <span class=\"token function\">install</span> <span class=\"token number\">2.1</span>.1\n<span class=\"token function\">sudo</span> gem <span class=\"token function\">install</span> fluentd --no-ri --no-rdoc\n<span class=\"token function\">sudo</span> fluentd -s</code></pre></div>\n<p>Now we have fluentd installed with sample configuration available in <code class=\"language-text\">/etc/fluentd/fluent.conf</code>.</p>\n<p>Since we would like our log entries to be pushed to elasticsearch we need a <a href=\"https://github.com/uken/fluent-plugin-elasticsearch\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">plugin</a> for that too:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">gem <span class=\"token function\">install</span> fluent-plugin-elasticsearch\ngem <span class=\"token function\">install</span> fluent-plugin-tail-multiline</code></pre></div>\n<p>Let’s edit <code class=\"language-text\">fluent.confg</code> file so that our agents reads sample log files from rails app and forwards them to elasticsearch instance:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">&lt;source&gt;\n  type tail_multiline\n  format /^(?&lt;level_short&gt;[^,]*), \\[(?&lt;time&gt;[^\\s]*) .(?&lt;request_id&gt;\\d+)\\]\\s+(?&lt;level&gt;[A-Z]+)[-\\s:]*(?&lt;message&gt;.*)/\n  path /path/to/log/file/staging.log\n  pos_file /path/to/positions/file/fluentd_tail.pos\n  tag app_name.environment\n&lt;/source&gt;\n\n&lt;match app_name.**&gt;\n  type elasticsearch\n  host machine-dns-name.cloudapp.net\n  logstash_format true\n  flush_interval 10s # for testing\n&lt;/match&gt;</code></pre></div>\n<p>The format we see above will following line of Rails log file:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">I, [2014-05-22T12:24:44.434963 #11837]  INFO -- : Completed 200 OK in 884ms (Views: 395.7ms | ActiveRecord: 115.0ms)</code></pre></div>\n<p>and break it down to following groups/fields:</p>\n<table class=\"table\">\n<thead>\n<tr><th>Key</th><th>Value</th></tr>\n</thead>\n<tbody>\n<tr>\n  <td>\n    time\n  </td>\n  <td>\n    2014/05/22 12:24:44\n  </td>\n</tr>\n<tr>\n  <td>\n    level_short\n  </td>\n  <td>\n    I\n  </td>\n</tr>\n<tr>\n  <td>\n    request_id\n  </td>\n  <td>\n    11837\n  </td>\n</tr>\n<tr>\n  <td>\n    level\n  </td>\n  <td>\n    INFO\n  </td>\n</tr>\n<tr>\n  <td>\n    message\n  </td>\n  <td>\n    Completed 200 OK in 884ms (Views: 395.7ms | ActiveRecord: 115.0ms)\n  </td>\n</tr>\n</tbody>\n</table>\n<p><em>Note that although builtin <code class=\"language-text\">in_tail</code> plugin supports multiline log entries I either don’t completely understand how to use it or there is no way to have full stack trace logged as a single message. Moreover <code class=\"language-text\">tail_multiline</code> doesn’t seem to support multiple input paths that’s why in order to monitor multiple files you would have to duplicate the source section.</em></p>\n<p>The only thing left is to start fluentd and watch our logs</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">rvmsudo fluetnd -d</code></pre></div>\n<h2 id=\"upstart-for-fluentd-elasticsearch-and-kibana-proxy\" style=\"position:relative;\"><a href=\"#upstart-for-fluentd-elasticsearch-and-kibana-proxy\" aria-label=\"upstart for fluentd elasticsearch and kibana proxy permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Upstart for fluentd, elasticsearch and kibana-proxy</h2>\n<p>The final thing we need to do is to setup above components to be run as services. Since we’re using Ubuntu for our servers we’ll use upstart congiurations for that.</p>\n<h3 id=\"upstart-for-fluentd\" style=\"position:relative;\"><a href=\"#upstart-for-fluentd\" aria-label=\"upstart for fluentd permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Upstart for fluentd</h3>\n<p>Since we have installed fluentd in ubuntu user rvm but we wan’t we have to generate a wrapper script for it</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">rvm wrapper default fluentd</code></pre></div>\n<p>and then use generated wrapper <code class=\"language-text\">~/.rvm/wrappers/default/fluentd</code> in our upstart script.\nLet’s create our upstart script and put it inside <code class=\"language-text\">/etc/init/fluetnd.conf</code></p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">description <span class=\"token string\">\"Fluentd\"</span>\nstart on runlevel <span class=\"token punctuation\">[</span><span class=\"token number\">2345</span><span class=\"token punctuation\">]</span> <span class=\"token comment\"># All except below</span>\nstop on runlevel <span class=\"token punctuation\">[</span>016<span class=\"token punctuation\">]</span> <span class=\"token comment\"># Halt, Single-User, Reboot</span>\nrespawn\nrespawn limit <span class=\"token number\">5</span> <span class=\"token number\">60</span> <span class=\"token comment\"># Restart if ended abruptly</span>\n<span class=\"token builtin class-name\">exec</span> <span class=\"token function\">sudo</span> -u ubuntu /home/ubuntu/.rvm/wrappers/default/fluentd</code></pre></div>\n<h3 id=\"upstart-for-elasticsearch\" style=\"position:relative;\"><a href=\"#upstart-for-elasticsearch\" aria-label=\"upstart for elasticsearch permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Upstart for elasticsearch</h3>\n<p>Elasticsearch already comes with a script for starting it in properly configured jvm we’ll utilize it in our upstart config <code class=\"language-text\">/etc/init/elasticsearch.conf</code></p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">description <span class=\"token string\">\"Elasticsearch\"</span>\nstart on runlevel <span class=\"token punctuation\">[</span><span class=\"token number\">2345</span><span class=\"token punctuation\">]</span> <span class=\"token comment\"># All except below</span>\nstop on runlevel <span class=\"token punctuation\">[</span>016<span class=\"token punctuation\">]</span> <span class=\"token comment\"># Halt, Single-User, Reboot</span>\nrespawn\nrespawn limit <span class=\"token number\">5</span> <span class=\"token number\">60</span> <span class=\"token comment\"># Restart if ended abruptly</span>\nsetuid ubuntu\n<span class=\"token builtin class-name\">exec</span> /path/to/your/elasticsearch/bin/elasticsearch</code></pre></div>\n<h3 id=\"upstart-for-kibana-proy\" style=\"position:relative;\"><a href=\"#upstart-for-kibana-proy\" aria-label=\"upstart for kibana proy permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Upstart for kibana-proy</h3>\n<p>With the <a href=\"#kibana_proxy_start\">kibana-proxy-start.sh</a> the upstart configuration for kibana-proxy is dead simple:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">description <span class=\"token string\">\"kibana-proxy\"</span>\nstart on runlevel <span class=\"token punctuation\">[</span><span class=\"token number\">2345</span><span class=\"token punctuation\">]</span> <span class=\"token comment\"># All except below</span>\nstop on runlevel <span class=\"token punctuation\">[</span>016<span class=\"token punctuation\">]</span> <span class=\"token comment\"># Halt, Single-User, Reboot</span>\nrespawn\nrespawn limit <span class=\"token number\">5</span> <span class=\"token number\">60</span> <span class=\"token comment\"># Restart if ended abruptly</span>\nchdir /where/you/installed/kibana-proxy\nsetuid ubuntu\n<span class=\"token builtin class-name\">exec</span> ./kibana-proxy-start.sh</code></pre></div>\n<h3 id=\"running-services\" style=\"position:relative;\"><a href=\"#running-services\" aria-label=\"running services permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Running services</h3>\n<p>Once you have your upstart scripts configuration ready you can now start services with a descriptive syntax:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">sudo</span> <span class=\"token function\">service</span> elasticsearch start</code></pre></div>\n<p>I you’re having trouble getting upstart to work you can always check its configuration with:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">initctl check-config</code></pre></div>\n<p>To find out why a particular service won’t start check out</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">dmesg</span> <span class=\"token operator\">|</span> <span class=\"token function\">grep</span> elasticsearch</code></pre></div>\n<p>Finally you can find you log files in <code class=\"language-text\">/var/log/upstart/servicename.*</code></p>\n<p>Now if you have setup everything correctly and of course you have some log messages generated by apps when you navigate to\n<a href=\"http://machine-dns-name.cloudapp.net/index.html#/dashboard/file/logstash.json\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">http://machine-dns-name.cloudapp.net/index.html#/dashboard/file/logstash.json</a> you should see a nice dashboard filling up with log entries:\n<img src=\"/images/kibana_in_action.png\"></p>","fields":{"slug":"/setting-up-fluentd-elasticsearch-and-kibana-on-azure/","tagSlugs":["/tag/fluentd/","/tag/kibana/","/tag/elasticsearch/"]},"excerpt":"A decent way too go through log files can come handy in various ways. From debugging bugs, investigating problems on production environment to figuring out where performance bottle necks are.\nFor simple cases when there is only one log file involved you can go very far with using grep/awk/sed magic or any decent editor…","frontmatter":{"date":"2014-06-08T00:00:00.000Z","description":null,"tags":["fluentd","kibana","elasticsearch"],"title":"Setting up fluentd elasticsearch and Kibana on azure","socialImage":null}}},"pageContext":{"slug":"/setting-up-fluentd-elasticsearch-and-kibana-on-azure/"}}}